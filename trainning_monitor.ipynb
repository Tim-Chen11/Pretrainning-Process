{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c7ab53",
   "metadata": {},
   "source": [
    "**2.3.5 Training Resilience & Monitoring**\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Monitor “Channel”-Specific Losses\n",
    "\n",
    "Track training loss **separately** on at least three data streams:\n",
    "\n",
    "* **Chinese knowledge** texts\n",
    "* **English knowledge** texts\n",
    "* **Code** snippets\n",
    "  This helps you spot imbalances or domain-specific issues early.\n",
    "\n",
    "### 2. Watch for Loss Spikes\n",
    "\n",
    "A **loss spike**—either a sudden jump or a sharp drop—often indicates corrupted or mis-formatted data.\n",
    "\n",
    "* **Sudden jump** (very high loss) can mean gibberish tokens or binary noise.\n",
    "* **Sudden drop** (very low loss) can mean empty lines, repeated tokens, or constant inputs.\n",
    "  Even if spikes don’t irreversibly damage the model, eliminating them leads to more stable convergence.\n",
    "\n",
    "### 3. Track Perplexity (PPL) on Sampled Validation Sets\n",
    "\n",
    "Perplexity trends tell you how well the model is learning natural-language structure:\n",
    "\n",
    "1. **Warm-up phase**: PPL often rises at first, then starts falling.\n",
    "2. **Plateau**: After initial drop, it may drift upward slightly.\n",
    "3. **Domain data**: When you introduce new, in-domain text, PPL should decline again.\n",
    "\n",
    "> **Practice**: From each distinct data source, randomly sample \\~200 examples and compute PPL periodically as your “health check.”\n",
    "\n",
    "### 4. Evaluate Few-Shot Prompting at Multiple Checkpoints\n",
    "\n",
    "Save model snapshots at different training steps and measure few-shot performance (e.g. accuracy on held-out tasks). This reveals which point gives you the best balance of general understanding and domain adaptation.\n",
    "\n",
    "---\n",
    "\n",
    "## What Is Perplexity?\n",
    "\n",
    "Perplexity is a standard metric in language modeling:\n",
    "\n",
    "$$\n",
    "\\mathrm{Perplexity}(\\mathrm{Model})\n",
    "= \\exp\\Bigl(-\\frac{1}{N}\\sum_{i=1}^N \\log P(w_i \\mid w_1,\\dots,w_{i-1})\\Bigr).\n",
    "$$\n",
    "\n",
    "Lower perplexity means the model predicts the next token more confidently and accurately.\n",
    "\n",
    "---\n",
    "\n",
    "## Remedies for Loss Spikes\n",
    "\n",
    "If you encounter a disruptive spike in training loss, consider the following fixes:\n",
    "\n",
    "1. **Rollback & resume**\n",
    "   Load the last checkpoint **before** the spike and continue training from there.\n",
    "   *(Technique borrowed from GLM-130B’s training report.)*\n",
    "\n",
    "2. **Reduce optimizer ε**\n",
    "   A smaller epsilon in Adam/AdamW can stabilize updates.\n",
    "\n",
    "3. **Scale down shallow-layer gradients**\n",
    "   Multiply gradients in the lower (early) layers by a small factor to damp abrupt updates.\n",
    "\n",
    "4. **Use the WSD scheduler**\n",
    "   The “Warmup–Steady–Decay” schedule (from miniCPM) can smooth out training transitions.\n",
    "\n",
    "5. **Apply z-loss regularization**\n",
    "   Add a small penalty on the logit normalizer (the “softmax z”) to prevent runaway softmax growth.\n",
    "\n",
    "---\n",
    "\n",
    "By systematically monitoring these signals and applying targeted remedies, you’ll maintain a robust, crash-resilient training process for your large-scale LLM.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
